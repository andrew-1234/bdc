---
title: "Prefilter"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Prefilter}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%",
  echo = TRUE,
  warning = FALSE,
  eval = T
)
```

## Introduction

Large and heterogeneous datasets may contain thousands of records missing spatial or taxonomic information (partially or entirely) as well as several records outside a region of interest or from doubtful sources. Such lower quality data are not fit for use in many research applications without prior amendments. The 'Pre-filter' step contains a series of of **tests to detect, remove, and, whenever, possible, correct such erroneous or suspect records**.

<br/>

<img src="https://img.icons8.com/windows/96/000000/box-important--v1.png" width="40"/> **Important**:

The results of **VALIDATION** test used to flag data quality is appended in separate fields in this database and retrieved as TRUE or FALSE, in which the former indicates correct records and the latter potentially problematic or suspect records.

## Installation

You can install the released version of 'BDC' from [github](https://github.com/brunobrr/bdc) with:

```{r, message=FALSE, warning=FALSE}
if (!require("remotes")) install.packages("remotes")
if (!require("bdc")) remotes::install_github("brunobrr/bdc")
```

Creating folders to save the results
```{r}
bdc::bdc_create_dir()
```


## Read the database

Read the merged database created in the step **Standardization and integration of different datasets** of the BDC workflow. It is also possible to read any datasets containing the **required** fields to run the workflow (more details [here](https://brunobrr.github.io/bdc/articles/integrate_datasets.html")

```{r}
database <-
  qs::qread("Output/Intermediate/00_merged_database.qs")
```

Standardization of character encoding
```{r}
for (i in 1:ncol(database)){
  if(is.character(database[,i])){
    Encoding(database[,i]) <- "UTF-8"
  }
}
```

<br/>

```{r echo=F, message=FALSE, warning=FALSE}
DT::datatable(
  database, class = 'stripe', extensions = 'FixedColumns',
  options = list(
    pageLength = 3,
    dom = 'Bfrtip',
    scrollX = TRUE,
    fixedColumns = list(leftColumns = 2)
  )
)
```

<br/>

## 1 - Records missing species names
*VALIDATION*. This test flags records missing species names

```{r}
check_pf <- bdc_scientificName_empty(
  data = database,
  sci_name = "scientificName")
```


## 2 - Records lacking information on geographic coordinates
*VALIDATION*. This test flags records missing partial or complete information on geographic coordinates.

```{r}
check_pf <- bdc_coordinates_empty(
  data = check_pf,
  lat = "decimalLatitude",
  lon = "decimalLongitude")
```


## 3 - Records with out-of-range coordinates
*VALIDATION*. This test flags records with out-of-range coordinates, that is latitude > 90 or -90; longitude >180 or -180.

```{r}
check_pf <- bdc_coordinates_outOfRange(
  data = check_pf,
  lat = "decimalLatitude",
  lon = "decimalLongitude")
```


## 4 - Records from distrustful sources
*VALIDATION*. This test flags records from doubtful source. For example, records from drawings, photographs, or multimedia objects, fossil records, among others.

```{r}
check_pf <- bdc_basisOfRrecords_notStandard(
  data = check_pf,
  basisOfRecord = "basisOfRecord",
  names_to_keep = "all")

```


## 5 - Getting country names from valid coordinates
*ENRICHMENT*. Deriving country names for records missing country names.

```{r}
check_pf <- bdc_country_from_coordinates(
  data = check_pf,
  lat = "decimalLatitude",
  lon = "decimalLongitude",
  country = "country")
```


## 6 - Standardizing country names and getting country code information
*ENRICHMENT*. Country names are standardized against a list of country names in several languages retrieved from Wikipedia.

```{r}
check_pf <- bdc_country_standardized(
  data = check_pf,
  country = "country"
)
```


## 7 - Correcting latitude and longitude transposed
*AMENDMENT*. The mismatch between informed country and coordinates can be the result of negative or transposed coordinates. Once detected a mismatch, different coordinate transformations are made to correct the country and coordinates mismatch. Verbatim coordinates are then replaced by the rectified ones in the returned database (a database containing verbatim and corrected coordinates is also created in the "Output" folder). Records near countries coastline are not tested to avoid incur in false positives.

```{r}
check_pf <-
  bdc_coordinates_transposed(
    data = check_pf,
    id = "database_id",
    sci_names = "scientificName",
    lat = "decimalLatitude",
    lon = "decimalLongitude",
    country = "country",
    countryCode = "countryCode", 
    border_buffer = 0.2 # in decimal degrees (~22 km at the equator)
  )
```


## 8 - Records outside a region of interest
*VALIDATION*. Records outside one or multiple reference countries; i.e., records in other countries or at an informed distance from the coast (e.g., in the ocean). This last step avoids flagging as invalid records close to country limits (e.g., records of coast or marshland species).

```{r}
check_pf <-
  bdc_coordinates_country_inconsistent(
    data = check_pf,
    country_name = "Brazil",
    lon = "decimalLongitude",
    lat = "decimalLatitude",
    dist = 0.1 # in decimal degrees (~11 km at the equator)
  )
```


## 9 - Save records not geo-referenced but with locality information
*ENRICHMENT*. Coordinates can be derived from a detailed description of the locality associated with records in a process called retrospective geo-referencing.

```{r}
xyFromLocality <- bdc_coordinates_from_locality(
  data = check_pf,
  locality = "locality",
  lon = "decimalLongitude",
  lat = "decimalLatitude"
)
```


## Report

Creating a column named ".summary" summarizing the results of all **VALIDATION** tests. This column is "FALSE" if any test was flagged as "FALSE" (i.e. potentially invalid or suspect record).

```{r}
check_pf <- bdc_summary_col(data = check_pf)
```

<br/>

```{r echo=F, message=FALSE, warning=FALSE}
DT::datatable(
  check_pf, class = 'stripe', extensions = 'FixedColumns',
  options = list(
    pageLength = 3,
    dom = 'Bfrtip',
    scrollX = TRUE,
    fixedColumns = list(leftColumns = 2)
  )
)
```

<br/>

Creating a report summarizing the results of all tests.

```{r}
report <-
  bdc_create_report(data = check_pf,
                    database_id = "database_id",
                    workflow_step = "prefilter")

report
```

<br/>

## Figures

Creating figures (bar plots and maps) to facilitate the interpretation of the results of data quality tests. See some examples below.

```{r}
bdc_create_figures(data = check_pf,
                   database_id = "database_id",
                   workflow_step = "prefilter")
```

<br/>

```{r echo=F, out.width="100%", out.height= "100%", fig.cap="Transposed coordinates"}
knitr::include_graphics(
  here::here(
    "inst",
    "extdata",
    "example_figures",
    "prefilter_coordinates_transposed_MAP.png"
  )
)
```

```{r echo=F, out.width="80%", out.height= "80%", fig.cap = "Coordinates and contry inconsistent"}
knitr::include_graphics(
  here::here(
    "inst",
    "extdata",
    "example_figures",
    "prefilter_.coordinates_country_inconsistent_MAP.png"
  )
)
```

```{r echo=F, out.width="80%", out.height= "80%", fig.cap = "Summary of all tests"}
knitr::include_graphics(
  here::here(
    "inst",
    "extdata",
    "example_figures",
    "prefilter_summary_all_tests_BAR.png"
  )
)
```

<br/>

## Filter the database

We can remove records flagged as erroneous or suspect. Records missing names or coordinates, outside a region of interest or from distrustful sources are rarely suitable to be used in biodiversity analyses. We will filter only valid records (flagged as TRUE) using the column ".summary". Next, we use the bdc_filter_out_falgs function to remove all tests' columns starting with ".").

```{r}
output <-
  check_pf %>%
  dplyr::filter(.summary == TRUE) %>%
  bdc_filter_out_flags(data = ., col_to_remove = "all")
```


## Save the database

```{r}
output %>%
  qs::qsave(.,
            here::here("Output", "Intermediate", "01_prefilter_database.qs"))
```
