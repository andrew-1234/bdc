---
title: "Time"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Time}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%",
  echo = TRUE,
  warning = FALSE,
  eval = T
)
```

## Introduction

This step of the BDC workflow extracts the collection year whenever possible from complete and legitimate date information, and flags dubious (e.g., 07/07/10), illegitimate (e.g., 1300, 2100), or not supplied (e.g., 0 or NA) collecting year.

<br/>

![](https://img.icons8.com/windows/96/000000/box-important--v1.png){width="40"} **Important**:

The results of **VALIDATION** test used to flag data quality is appended in separate fields in this database and retrieved as TRUE or **FALSE**, in which the former indicates correct records and the **latter potentially problematic or suspect records.**

## Installation

You can install the released version of BDC from [github](https://github.com/brunobrr/bdc) with:

```{r, message=FALSE, warning=FALSE}
if (!require("remotes")) install.packages("remotes")
if (!require("bdc")) remotes::install_github("brunobrr/bdc")
```

### Read the database

Read the database created in the [**Space**](https://brunobrr.github.io/bdc/articles/03_space.html) step of the BDC workflow. It is also possible to read any datasets containing the \*\*required\*\* fields to run the workflow (more details [here](%5Bhttps://brunobrr.github.io/bdc/articles/integrate_datasets.html%22)).

```{r}
database <-
  qs::qread(here::here("Output/Intermediate/03_space_database.qs"))
```

Standardization of character encoding.

```{r}
for (i in 1:ncol(database)){
  if(is.character(database[,i])){
    Encoding(database[,i]) <- "UTF-8"
  }
}
```

<br/>

```{r echo=F, message=FALSE, warning=FALSE}
DT::datatable(
  database, class = 'stripe', extensions = 'FixedColumns',
  options = list(
    pageLength = 3,
    dom = 'Bfrtip',
    scrollX = TRUE,
    fixedColumns = list(leftColumns = 2)
  )
)
```

## 1 - Records lacking event date information

*VALIDATION*. This function flags records lacking event date information (e.g., empty or NA).

```{r}
check_time <-
  bdc_eventDate_empty(data = database, eventDate = "verbatimEventDate")
```

## 2 - Extract year from event date

*ENRICHMENT*. This function extracts four-digit year from unambiguously interpretable collecting dates.

```{r}
check_time <-
  bdc_year_from_eventDate(data = check_time, eventDate = "verbatimEventDate")
```

## 3 - Records with out-of-range collecting year

*VALIDATION*. This function identifies records with illegitimate or potentially imprecise collecting year. The year provided can be out-of-range (e.g., in the future) or collected before a specified year supplied by the user (e.g., 1900). Older records are more likely to be imprecise due to the locality-derived geo-referencing process.

```{r}
check_time <-
  bdc_year_outOfRange(data = check_time,
                      eventDate = "year",
                      year_threshold = 1900)
```

## Report

Creating a column named **.summary** summing up the results of all **VALIDATION** tests. This column is **FALSE** witharecord is flagged as FALSE in any data quality test (i.e. potentially invalid or suspect record).

```{r}
check_time <- bdc_summary_col(data = check_time)
```

<br/>

```{r echo=F, message=FALSE, warning=FALSE}
DT::datatable(
  check_time, class = 'stripe', extensions = 'FixedColumns',
  options = list(
    pageLength = 3,
    dom = 'Bfrtip',
    scrollX = TRUE,
    fixedColumns = list(leftColumns = 2)
  )
)
```

<br/>

Creating a report summarizing the results of all tests of the BDC workflow

```{r}
report <-
  bdc_create_report(data = check_time,
                    database_id = "database_id",
                    workflow_step = "time")

report
```

<br/>

## Figures

Creating a histogram showing the number of records collecting over the years.

```{r}
bdc_create_figures(data = check_time,
                   database_id = "database_id",
                   workflow_step = "time")
```

<br/>

![Number of records sampled over the years](https://github.com/brunobrr/bdc/raw/master/vignettes/inst/extdata/example_figures/time_year_BAR.png){width="20cm"}

<br/>

![Summary of all tests of the time step; note that some database lack event date information](https://github.com/brunobrr/bdc/raw/master/vignettes/inst/extdata/example_figures/time_.summary_BAR.png){width="20cm"}

<br/>

![Summary of all validation tests of the BDC workflow](https://github.com/brunobrr/bdc/raw/master/vignettes/inst/extdata/example_figures/time_summary_all_tests_BAR.png){width="20cm"}

<br/>

## Save a "raw" database

Save the original database containing the results of all data quality tests appended in separate columns.

```{r}
check_time %>%
  qs::qsave(.,
            here::here("Output", "Intermediate", "04_time_raw_database.qs"))
```

## Filter the database

Let's remove potentially erroneous or suspect records flagged by the data quality tests applied in all steps of the BDC workflow to get a "clean", "fitness-for-use" database. Note that **29%** (2,631 out of 9.000 records) of original records were considered "fitness-for-use" after the data-cleaning process.

```{r}
output <-
  check_time %>%
  dplyr::filter(.summary == TRUE) %>%
  bdc_filter_out_flags(data = ., col_to_remove = "all")
```

## Save a "fitness-for-use" database

```{r}
output %>%
  qs::qsave(.,
            here::here("Output", "Intermediate", "04_time_clean_database.qs"))
```

<br/>

```{r echo=F, message=FALSE, warning=FALSE}
DT::datatable(
  output, class = 'stripe', extensions = 'FixedColumns',
  options = list(
    pageLength = 3,
    dom = 'Bfrtip',
    scrollX = TRUE,
    fixedColumns = list(leftColumns = 2)
  )
)
```
