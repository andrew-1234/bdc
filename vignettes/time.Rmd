---
title: "Prefilter"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Prefilter}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, eval = FALSE)
devtools::load_all()
```


### Introduction

This step of the BDC workflow extracts the collection year whenever possible from complete and legitimate date information, and flags dubious (e.g., 07/07/10), illegitimate (e.g., 1300, 2100), or not supplied (e.g., 0 or NA) collecting year.

<br/>

<img src="https://img.icons8.com/windows/96/000000/box-important--v1.png" width="40"/> **Important**:

The results of *validation* test used to flag data quality is appended in separate fields in this database and retrieved as TRUE or FALSE, in which the former indicates correct records and the latter potentially problematic or suspect records. 

### Installation

You can install the released version of 'BDC' from [github](https://github.com/brunobrr/bdc) with:

```{r, message=FALSE, warning=FALSE}
if (!require("remotes")) install.packages("remotes")
if (!require("bdc")) remotes::install_github("brunobrr/bdc")
```

Creating folders to save the results
```{r}
bdc::bdc_create_dir()
```


### Read the database
Read the merged database created in the step **Standardization and integration of different datasets** of the BDC workflow. It is also possible to read any datasets containing the *required* fields to run the workflow.

```{r}
database <-
  system.file("extdata",
              "Output",
              "Intermediate/03_space_database.qs", package = "bdc") %>%
  readr::read_csv(database)

head(database)
```

Standardization of character encoding
```{r}
for (i in 1:ncol(database)){
  if(is.character(database[,i])){
    Encoding(database[,i]) <- "UTF-8"
  }
}
```


### 1 - Records lacking event date information
*validation*. This function flags records lacking event date information (e.g., empty or NA).

```{r}
check_time <-
  bdc_eventDate_empty(data = database, eventDate = "verbatimEventDate")
```


### 2 - Extract year from event date
*enrichment*. This function extracts four-digit year from unambiguously interpretable collecting dates.

```{r}
check_time <-
  bdc_year_from_eventDate(data = check_time, eventDate = "verbatimEventDate")
```


### 3 - Records with out-of-range collecting year
*validation*. This function identifies records with illegitimate or potentially imprecise collecting year. The year provided can be out-of-range (e.g., in the future) or collected before a specified year supplied by the user (e.g., 1900).  Older records are more likely to be imprecise due to the locality-derived geo-referencing process.

```{r}
check_time <-
  bdc_year_outOfRange(data = check_time,
                      eventDate = "year",
                      year_threshold = 1900)
```



### Report
Creating a column named ".summary" summarizing the results of all "validation" tests. This column is "FALSE" if any test was flagged as "FALSE" (i.e. potentially invalid or suspect record).

```{r}
check_time <- bdc_summary_col(data = check_time)
```


Creating a report summarizing the results of all tests.

```{r}
report <-
  bdc_create_report(data = check_time,
                    database_id = "database_id",
                    workflow_step = "time")

report
```


### Figures
Creating histogram showing the number of records collecting over the years.

```{r}
bdc_create_figures(data = check_time,
                   database_id = "database_id",
                   workflow_step = "time")
```

### Save a "raw" database
Save the original database containing the results of each data quality tests appended in separate columns.

```{r}
check_time %>% 
  qs::qsave(., 
            here::here("Output", "Intermediate", "04_time_raw_database.qs"))
```


### Filter the database
Let's remove potentially erroneous or suspect records flagged by the data quality tests applied in all steps of the BDC workflow to get a "clean", "fitness-for-use" database. 

```{r}
output <-
  check_time %>%
  dplyr::filter(.summary == TRUE) %>%
  bdc_filter_out_flags(data = ., col_to_remove = "all")
```


### Save a "fitness-for-use" database
```{r}
check_pf %>% 
  qs::qsave(., 
            here::here("Output", "Intermediate", "04_time_clean_database.qs"))
```

