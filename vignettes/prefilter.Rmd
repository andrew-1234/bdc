---
title: "Prefilter"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Prefilter}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%"
)
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, eval = FALSE)
devtools::load_all()
```


### Introduction

Large and heterogeneous datasets may contain thousands of records missing spatial or taxonomic information (partially or entirely) as well as several records outside a region of interest. Such lower quality data are not fit for use in many research applications without prior amendments. The 'Pre-filter' step contains a series of of tests to detect and, whenever, possible, correct errorouns records.

<br/>

<img src="https://img.icons8.com/windows/96/000000/box-important--v1.png" width="40"/> **Important**:

The results of *validation* test used to flag data quality is appended in separate fields in this database and retrieved as TRUE or FALSE, in which the former indicates correct records and the latter potentially problematic or suspect records. 

### Installation

You can install the released version of 'BDC' from [github](https://github.com/brunobrr/bdc) with:

```{r, message=FALSE, warning=FALSE}
if (!require("remotes")) install.packages("remotes")
if (!require("bdc")) remotes::install_github("brunobrr/bdc")
```

Creating folders to save the results
```{r}
bdc::bdc_create_dir()
```


### Read the database
Read the merged database created in the step **Standardization and integration of different datasets** of the BDC workflow. It is also possible to read any datasets containing the *required* fields to run the workflow.

```{r}
database <-
  system.file("extdata",
              "Output",
              "Intermediate/00_merged_database.qs", package = "bdc") %>%
  readr::read_csv(database)

head(database)
```

Standardization of character encoding
```{r}
for (i in 1:ncol(database)){
  if(is.character(database[,i])){
    Encoding(database[,i]) <- "UTF-8"
  }
}
```


### 1 - Records missing species names
*Validation*. This test flags records missing species names 
```{r}
check_pf <- bdc_scientificName_empty(
  data = database,
  sci_name = "scientificName")
```


### 2 - Records lacking information on geographic coordinates
*Validation*. This test flags records missing partial or complete information on geographic coordinates.

```{r}
check_pf <- bdc_coordinates_empty(
  data = check_pf1,
  lat = "decimalLatitude",
  lon = "decimalLongitude")
```


### 3 - Records with out-of-range coordinates 
*Validation*. This test flags records with out-of-range coordinates, that is latitude > 90 or -90; longitude >180 or -180.

```{r}
check_pf <- bdc_coordinates_outOfRange(
  data = check_pf2,
  lat = "decimalLatitude",
  lon = "decimalLongitude")
```


### 4 - Records from distrustful sources 
*Validation*. This test flags records from doubtful source. For example, records from drawings, photographs, or multimedia objects, fossil records, among others.

```{r}
check_pf <- bdc_basisOfRrecords_notStandard(
  data = check_pf3,
  basisOfRecord = "basisOfRecord",
  names_to_keep = "all")

```


### 5 - Getting country names from valid coordinates
*ENRICHMENT*. Deriving country names for records missing country names.
```{r}
check_pf <- bdc_country_from_coordinates(
  data = check_pf4,
  lat = "decimalLatitude",
  lon = "decimalLongitude",
  country = "country")
```


### 6 - Standardizing country names and getting country code information
*ENRICHMENT*. Country names are standardized against a list of country names in several languages retrieved from Wikipedia.

```{r}
check_pf <- bdc_country_standardized(
  data = check_pf5,
  country = "country"
)
```


### 7 - Correcting latitude and longitude transposed
*AMENDMENT*. The mismatch between informed country and coordinates can be the result of negative or transposed coordinates. Once detected a mismatch, different coordinate transformations are made to correct the country and coordinates mismatch. Verbatim coordinates are then replaced by the rectified ones in the returned database (a database containing verbatim and corrected coordinates is also created in the "Output" folder).

```{r}
check_pf <-
  bdc_coordinates_transposed(
    data = check_pf6, 
    id = "database_id",
    sci_names = "scientificName",
    lon = "decimalLongitude",
    lat = "decimalLatitude",
    country = "country"
  )
```


### 8 - Records outside a region of interest
*Validation*. Records outside one or multiple reference countries; i.e., records in other countries or at an informed distance from the coast (e.g., in the ocean). This last step avoids flagging as invalid records close to country limits (e.g., records of coast or marshland species).

```{r}
check_pf <-
  bdc_coordinates_country_inconsistent(
    data = check_pf7,
    country_name = "Brazil",
    lon = "decimalLongitude",
    lat = "decimalLatitude",
    dist = 0.1 # in decimal degrees (~11 km at the equator)
  )
```


### 9 - Save records not geo-referenced but with locality information
*ENRICHMENT*. Coordinates can be derived from a detailed description of the locality associated with records in a process called retrospective geo-referencing.

```{r}
bdc_coordinates_from_locality(
  data = check_pf8,
  locality = "locality",
  lon = "decimalLongitude",
  lat = "decimalLatitude"
)
```


### Report
Creating a column named ".summary" summarizing the results of all "validation" tests. This column is "FALSE" if any test was flagged as "FALSE" (i.e. potentially invalid or suspect record).

```{r}
check_pf <- bdc_summary_col(data = check_pf)
```


Creating a report summarizing the results of all tests.

```{r}
report <-
  bdc_create_report(data = check_pf,
                    database_id = "database_id",
                    workflow_step = "prefilter")

report
```


### Figures
Creating figures (bar plots and maps) to facilitate the interpretation of the results of data quality tests.

```{r}
bdc_create_figures(data = check_pf,
                   database_id = "database_id",
                   workflow_step = "prefilter")
```


### Filter the database
It is possible to removed flagged records (potentially problematic ones) to get a 'clean' database (i.e., without test columns starting with "."). However, to ensure that all records be evaluated in all the data quality tests (i.e., tests of the taxonomic, spatial, and temporal steps of the workflow), potentially erroneous or suspect records will be removed in the final step of the workflow.

```{r}
# output <-
#   check_pf %>%
#   dplyr::filter(.summary == TRUE) %>%
#   bdc_filter_out_flags(data = ., col_to_remove = "all")
```


### Save the database

```{r}
check_pf %>% 
  qs::qsave(., 
            here::here("Output", "Intermediate", "01_prefilter_database.qs"))
```
